{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68ce15c-a0ca-405a-8dab-685a2e2126a2",
   "metadata": {},
   "source": [
    "# Snakemake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9ca36-ab7b-4f57-9479-007031cb8548",
   "metadata": {},
   "source": [
    "In order to start working on a pipeline, the first thing is to make sure that all the tools, software or codes are installed within an environment. We will write a small pipeline in snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37215161-515e-4186-9693-959045c7ee6f",
   "metadata": {},
   "source": [
    "https://anaconda.org/bioconda/snakemake\n",
    "https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a17a9-5d87-4703-8165-59938eee8e2d",
   "metadata": {},
   "source": [
    "Notes on direction of the lecture.\n",
    "\n",
    "1. First we need to make a hands-on implementation in snakemake\n",
    "2. We can learn about different kind of python implementations. For example, look at my thesis work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aaf82d",
   "metadata": {},
   "source": [
    "### setting up conda enviornment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643609fb",
   "metadata": {},
   "source": [
    "conda create -n smk\n",
    "\n",
    "conda activate smk\n",
    "\n",
    "conda install bioconda::snakemake\n",
    "\n",
    "conda install -n smk ipykernel\n",
    "\n",
    "conda install -n smk nb_conda_kernels\n",
    "\n",
    "conda install -n smk anaconda::jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2661cb",
   "metadata": {},
   "source": [
    "https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108e369",
   "metadata": {},
   "source": [
    "Let's have a look at what we are trying to achieve here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cba8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mrinalmanu/Documents/notebooks_python/snakemake_zero\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d013ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\tconfig.json  input  notebook_8_snakemake.ipynb\tsnakefile.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69804f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘input’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdfa4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch input/instructions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "436482b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instructions.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "349df422",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head input/instructions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1edc17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Some text here.\" > input/instructions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1cb19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some text here.\r\n"
     ]
    }
   ],
   "source": [
    "!head input/instructions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc76b83",
   "metadata": {},
   "source": [
    "What if we just tried to concatenate to a file that does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49023906",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Some more text here.\" > input/instructions2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af8b853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some more text here.\r\n"
     ]
    }
   ],
   "source": [
    "!head input/instructions2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135aaa1",
   "metadata": {},
   "source": [
    "We can look a bit at logging in python as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c448de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instructions.txt  instructions2.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls input\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77d38fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat input/*.txt >> output/combined_instructions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08909da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some text here.\r\n",
      "Some more text here.\r\n"
     ]
    }
   ],
   "source": [
    "!head output/combined_instructions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd63847",
   "metadata": {},
   "source": [
    "Let's try to implement a rule in snakemake for the same task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa08e0",
   "metadata": {},
   "source": [
    "If you want to set a version requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13d6ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snakemake.utils import min_version\n",
    "min_version(\"2.3.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118f0fc",
   "metadata": {},
   "source": [
    "First we describe what will be the final output."
   ]
  },
  {
   "cell_type": "raw",
   "id": "689835e7",
   "metadata": {},
   "source": [
    "rule all:\n",
    "    \"\"\"\n",
    "    Collect the main outputs of the workflow.\n",
    "    \"\"\"\n",
    "    input:\n",
    "        \"output/combined_instructions.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf494e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "985f1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in range(0,10):\n",
    "    name.append('{}.txt'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9241bce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.txt',\n",
       " '1.txt',\n",
       " '2.txt',\n",
       " '3.txt',\n",
       " '4.txt',\n",
       " '5.txt',\n",
       " '6.txt',\n",
       " '7.txt',\n",
       " '8.txt',\n",
       " '9.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb5109",
   "metadata": {},
   "source": [
    "We need to redirect an output to these files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b6591",
   "metadata": {},
   "source": [
    "\n",
    "rule append_text:\n",
    "    \"\"\"\n",
    "    Append text to a file.\n",
    "    \"\"\"\n",
    "    output:\n",
    "        \"input/{name}\"\n",
    "    shell:\n",
    "        \"\"\"\n",
    "        echo \"Appended {name}\" >> {name}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d76f92",
   "metadata": {},
   "source": [
    "Now we can write a rule for combining these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ff206",
   "metadata": {},
   "source": [
    "rule concat_files:\n",
    "    \"\"\"\n",
    "    Append text to a file.\n",
    "    \"\"\"\n",
    "    output:\n",
    "        \"output/combined_instructions.txt\"\n",
    "    shell:\n",
    "        \"\"\"\n",
    "        cat output/.*txt >> output/combined_instructions.txt\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41502e16",
   "metadata": {},
   "source": [
    "We can generate a rulegraph at the end to check how it all going."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f3a63",
   "metadata": {},
   "source": [
    "rule generate_rulegraph:\n",
    "    \"\"\"\n",
    "    Generate a rulegraph for the workflow.\n",
    "    \"\"\"\n",
    "    output:\n",
    "        \"results/rulegraph.png\"\n",
    "    shell:\n",
    "        \"\"\"\n",
    "        snakemake --snakefile snakefile.smk --config max_reads=0 --rulegraph | dot -Tpng > {output}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a4c8c",
   "metadata": {},
   "source": [
    "Now we can look at how to launch this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3187850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\tconfig.json  input  notebook_8_snakemake.ipynb\toutput\tsnakefile.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e7626b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"samples\": [\"1\",\"2\",\"3\"]}"
     ]
    }
   ],
   "source": [
    "!head -300 config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "721ad438",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from snakemake.utils import min_version\r\n",
      "min_version(\"2.3.0\") \r\n",
      "# actually you should use versions higher than 5.11, they have lint\r\n",
      "# lint helps a lot with debugging\r\n",
      "\r\n",
      "configfile: \"config.json\"\r\n",
      "\r\n",
      "# usually sankemake checks if the output already exists, to avoid\r\n",
      "# re-running the pipeline, this is why there is always an \"all\" rule\r\n",
      "\r\n",
      "SAMPLES = config['samples']\r\n",
      "        \r\n",
      "rule all:\r\n",
      "    \"\"\"\r\n",
      "    Collect the main inputs and outputs of the workflow.\r\n",
      "    \"\"\"\r\n",
      "    input:\r\n",
      "        \"combined_instructions.txt\"\r\n",
      "\r\n",
      "    \r\n",
      "rule touch_files:\r\n",
      "    \"\"\"\r\n",
      "    Create a file.\r\n",
      "    \"\"\"\r\n",
      "    output:\r\n",
      "        \"{sample}.txt\"\r\n",
      "    shell:\r\n",
      "        \"\"\"\r\n",
      "        touch {output} && printf \"Hello! {output} \" >> {output}\r\n",
      "        \"\"\"\r\n",
      "\r\n",
      "rule concat_files:\r\n",
      "    input:\r\n",
      "        files=expand(\"{sample}.txt\", sample=SAMPLES),\r\n",
      "    output:\r\n",
      "        \"combined_instructions.txt\",\r\n",
      "    params:\r\n",
      "        cmd=\"cat\",\r\n",
      "    shell:\r\n",
      "        \"\"\"\r\n",
      "        {params.cmd} {input.files} >> {output}\r\n",
      "        \"\"\"\r\n",
      "\r\n",
      "rule generate_rulegraph:\r\n",
      "    output:\r\n",
      "        \"results/rulegraph.png\",\r\n",
      "    shell:\r\n",
      "        \"\"\"\r\n",
      "        snakemake --snakefile snakefile_mrsa.smk --config max_reads=0 --rulegraph | dot -Tpng > {output}\r\n",
      "        \"\"\""
     ]
    }
   ],
   "source": [
    "!head -300 snakefile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d848dc4",
   "metadata": {},
   "source": [
    "To run snakemake with a specific snakefile, you can call it with the -s or --snakefile command line arg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57ba8568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: snakemake [-h] [--snakefile FILE] [--gui [PORT]] [--cores [N]]\r\n",
      "                 [--local-cores N] [--resources [NAME=INT [NAME=INT ...]]]\r\n",
      "                 [--config [KEY=VALUE [KEY=VALUE ...]]] [--configfile FILE]\r\n",
      "                 [--list] [--list-target-rules] [--directory DIR] [--dryrun]\r\n",
      "                 [--printshellcmds] [--debug-dag] [--dag]\r\n",
      "                 [--force-use-threads] [--rulegraph] [--d3dag] [--summary]\r\n",
      "                 [--detailed-summary] [--archive FILE] [--touch]\r\n",
      "                 [--keep-going] [--force] [--forceall]\r\n",
      "                 [--forcerun [TARGET [TARGET ...]]]\r\n",
      "                 [--prioritize TARGET [TARGET ...]]\r\n",
      "                 [--until TARGET [TARGET ...]]\r\n",
      "                 [--omit-from TARGET [TARGET ...]] [--allow-ambiguity]\r\n",
      "                 [--cluster CMD | --cluster-sync CMD | --drmaa [ARGS]]\r\n",
      "                 [--drmaa-log-dir DIR] [--cluster-config FILE]\r\n",
      "                 [--immediate-submit] [--jobscript SCRIPT] [--jobname NAME]\r\n",
      "                 [--reason] [--stats FILE] [--nocolor] [--quiet] [--nolock]\r\n",
      "                 [--unlock] [--cleanup-metadata FILE [FILE ...]]\r\n",
      "                 [--rerun-incomplete] [--ignore-incomplete]\r\n",
      "                 [--list-version-changes] [--list-code-changes]\r\n",
      "                 [--list-input-changes] [--list-params-changes]\r\n",
      "                 [--latency-wait SECONDS] [--wait-for-files [FILE [FILE ...]]]\r\n",
      "                 [--benchmark-repeats N] [--notemp] [--keep-remote]\r\n",
      "                 [--keep-target-files] [--keep-shadow]\r\n",
      "                 [--allowed-rules ALLOWED_RULES [ALLOWED_RULES ...]]\r\n",
      "                 [--max-jobs-per-second MAX_JOBS_PER_SECOND]\r\n",
      "                 [--restart-times RESTART_TIMES] [--timestamp]\r\n",
      "                 [--greediness GREEDINESS] [--no-hooks] [--print-compilation]\r\n",
      "                 [--overwrite-shellcmd OVERWRITE_SHELLCMD] [--verbose]\r\n",
      "                 [--debug] [--profile FILE] [--mode {0,1,2}]\r\n",
      "                 [--bash-completion] [--use-conda] [--conda-prefix DIR]\r\n",
      "                 [--wrapper-prefix WRAPPER_PREFIX]\r\n",
      "                 [--default-remote-provider {S3,GS,SFTP,S3Mocked}]\r\n",
      "                 [--default-remote-prefix DEFAULT_REMOTE_PREFIX] [--version]\r\n",
      "                 [target [target ...]]\r\n",
      "\r\n",
      "Snakemake is a Python based language and execution environment for GNU Make-\r\n",
      "like workflows.\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  target                Targets to build. May be rules or files.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --snakefile FILE, -s FILE\r\n",
      "                        The workflow definition in a snakefile.\r\n",
      "  --gui [PORT]          Serve an HTML based user interface to the given port\r\n",
      "                        (default: 8000). If possible, a browser window is\r\n",
      "                        opened.\r\n",
      "  --cores [N], --jobs [N], -j [N]\r\n",
      "                        Use at most N cores in parallel (default: 1). If N is\r\n",
      "                        omitted, the limit is set to the number of available\r\n",
      "                        cores.\r\n",
      "  --local-cores N       In cluster mode, use at most N cores of the host\r\n",
      "                        machine in parallel (default: number of CPU cores of\r\n",
      "                        the host). The cores are used to execute local rules.\r\n",
      "                        This option is ignored when not in cluster mode.\r\n",
      "  --resources [NAME=INT [NAME=INT ...]], --res [NAME=INT [NAME=INT ...]]\r\n",
      "                        Define additional resources that shall constrain the\r\n",
      "                        scheduling analogously to threads (see above). A\r\n",
      "                        resource is defined as a name and an integer value.\r\n",
      "                        E.g. --resources gpu=1. Rules can use resources by\r\n",
      "                        defining the resource keyword, e.g. resources: gpu=1.\r\n",
      "                        If now two rules require 1 of the resource 'gpu' they\r\n",
      "                        won't be run in parallel by the scheduler.\r\n",
      "  --config [KEY=VALUE [KEY=VALUE ...]], -C [KEY=VALUE [KEY=VALUE ...]]\r\n",
      "                        Set or overwrite values in the workflow config object.\r\n",
      "                        The workflow config object is accessible as variable\r\n",
      "                        config inside the workflow. Default values can be set\r\n",
      "                        by providing a JSON file (see Documentation).\r\n",
      "  --configfile FILE     Specify or overwrite the config file of the workflow\r\n",
      "                        (see the docs). Values specified in JSON or YAML\r\n",
      "                        format are available in the global config dictionary\r\n",
      "                        inside the workflow.\r\n",
      "  --list, -l            Show availiable rules in given Snakefile.\r\n",
      "  --list-target-rules, --lt\r\n",
      "                        Show available target rules in given Snakefile.\r\n",
      "  --directory DIR, -d DIR\r\n",
      "                        Specify working directory (relative paths in the\r\n",
      "                        snakefile will use this as their origin).\r\n",
      "  --dryrun, -n          Do not execute anything.\r\n",
      "  --printshellcmds, -p  Print out the shell commands that will be executed.\r\n",
      "  --debug-dag           Print candidate and selected jobs (including their\r\n",
      "                        wildcards) while inferring DAG. This can help to debug\r\n",
      "                        unexpected DAG topology or errors.\r\n",
      "  --dag                 Do not execute anything and print the directed acyclic\r\n",
      "                        graph of jobs in the dot language. Recommended use on\r\n",
      "                        Unix systems: snakemake --dag | dot | display\r\n",
      "  --force-use-threads   Force threads rather than processes. Helpful if shared\r\n",
      "                        memory (/dev/shm) is full or unavailable.\r\n",
      "  --rulegraph           Do not execute anything and print the dependency graph\r\n",
      "                        of rules in the dot language. This will be less\r\n",
      "                        crowded than above DAG of jobs, but also show less\r\n",
      "                        information. Note that each rule is displayed once,\r\n",
      "                        hence the displayed graph will be cyclic if a rule\r\n",
      "                        appears in several steps of the workflow. Use this if\r\n",
      "                        above option leads to a DAG that is too large.\r\n",
      "                        Recommended use on Unix systems: snakemake --rulegraph\r\n",
      "                        | dot | display\r\n",
      "  --d3dag               Print the DAG in D3.js compatible JSON format.\r\n",
      "  --summary, -S         Print a summary of all files created by the workflow.\r\n",
      "                        The has the following columns: filename, modification\r\n",
      "                        time, rule version, status, plan. Thereby rule version\r\n",
      "                        contains the versionthe file was created with (see the\r\n",
      "                        version keyword of rules), and status denotes whether\r\n",
      "                        the file is missing, its input files are newer or if\r\n",
      "                        version or implementation of the rule changed since\r\n",
      "                        file creation. Finally the last column denotes whether\r\n",
      "                        the file will be updated or created during the next\r\n",
      "                        workflow execution.\r\n",
      "  --detailed-summary, -D\r\n",
      "                        Print a summary of all files created by the workflow.\r\n",
      "                        The has the following columns: filename, modification\r\n",
      "                        time, rule version, input file(s), shell command,\r\n",
      "                        status, plan. Thereby rule version contains the\r\n",
      "                        versionthe file was created with (see the version\r\n",
      "                        keyword of rules), and status denotes whether the file\r\n",
      "                        is missing, its input files are newer or if version or\r\n",
      "                        implementation of the rule changed since file\r\n",
      "                        creation. The input file and shell command columns are\r\n",
      "                        selfexplanatory. Finally the last column denotes\r\n",
      "                        whether the file will be updated or created during the\r\n",
      "                        next workflow execution.\r\n",
      "  --archive FILE        Archive the workflow into the given tar archive FILE.\r\n",
      "                        The archive will be created such that the workflow can\r\n",
      "                        be re-executed on a vanilla system. The function needs\r\n",
      "                        conda and git to be installed. It will archive every\r\n",
      "                        file that is under git version control. Note that it\r\n",
      "                        is best practice to have the Snakefile, config files,\r\n",
      "                        and scripts under version control. Hence, they will be\r\n",
      "                        included in the archive. Further, it will add input\r\n",
      "                        files that are not generated by by the workflow itself\r\n",
      "                        and conda environments. Note that symlinks are\r\n",
      "                        dereferenced. Supported formats are .tar, .tar.gz,\r\n",
      "                        .tar.bz2 and .tar.xz.\r\n",
      "  --touch, -t           Touch output files (mark them up to date without\r\n",
      "                        really changing them) instead of running their\r\n",
      "                        commands. This is used to pretend that the rules were\r\n",
      "                        executed, in order to fool future invocations of\r\n",
      "                        snakemake. Fails if a file does not yet exist.\r\n",
      "  --keep-going, -k      Go on with independent jobs if a job fails.\r\n",
      "  --force, -f           Force the execution of the selected target or the\r\n",
      "                        first rule regardless of already created output.\r\n",
      "  --forceall, -F        Force the execution of the selected (or the first)\r\n",
      "                        rule and all rules it is dependent on regardless of\r\n",
      "                        already created output.\r\n",
      "  --forcerun [TARGET [TARGET ...]], -R [TARGET [TARGET ...]]\r\n",
      "                        Force the re-execution or creation of the given rules\r\n",
      "                        or files. Use this option if you changed a rule and\r\n",
      "                        want to have all its output in your workflow updated.\r\n",
      "  --prioritize TARGET [TARGET ...], -P TARGET [TARGET ...]\r\n",
      "                        Tell the scheduler to assign creation of given targets\r\n",
      "                        (and all their dependencies) highest priority.\r\n",
      "                        (EXPERIMENTAL)\r\n",
      "  --until TARGET [TARGET ...], -U TARGET [TARGET ...]\r\n",
      "                        Runs the pipeline until it reaches the specified rules\r\n",
      "                        or files. Only runs jobs that are dependencies of the\r\n",
      "                        specified rule or files, does not run sibling DAGs.\r\n",
      "  --omit-from TARGET [TARGET ...], -O TARGET [TARGET ...]\r\n",
      "                        Prevent the execution or creation of the given rules\r\n",
      "                        or files as well as any rules or files that are\r\n",
      "                        downstream of these targets in the DAG. Also runs jobs\r\n",
      "                        in sibling DAGs that are independent of the rules or\r\n",
      "                        files specified here.\r\n",
      "  --allow-ambiguity, -a\r\n",
      "                        Don't check for ambiguous rules and simply use the\r\n",
      "                        first if several can produce the same file. This\r\n",
      "                        allows the user to prioritize rules by their order in\r\n",
      "                        the snakefile.\r\n",
      "  --cluster CMD, -c CMD\r\n",
      "                        Execute snakemake rules with the given submit command,\r\n",
      "                        e.g. qsub. Snakemake compiles jobs into scripts that\r\n",
      "                        are submitted to the cluster with the given command,\r\n",
      "                        once all input files for a particular job are present.\r\n",
      "                        The submit command can be decorated to make it aware\r\n",
      "                        of certain job properties (input, output, params,\r\n",
      "                        wildcards, log, threads and dependencies (see the\r\n",
      "                        argument below)), e.g.: $ snakemake --cluster 'qsub\r\n",
      "                        -pe threaded {threads}'.\r\n",
      "  --cluster-sync CMD    cluster submission command will block, returning the\r\n",
      "                        remote exitstatus upon remote termination (for\r\n",
      "                        example, this should be usedif the cluster command is\r\n",
      "                        'qsub -sync y' (SGE)\r\n",
      "  --drmaa [ARGS]        Execute snakemake on a cluster accessed via DRMAA,\r\n",
      "                        Snakemake compiles jobs into scripts that are\r\n",
      "                        submitted to the cluster with the given command, once\r\n",
      "                        all input files for a particular job are present. ARGS\r\n",
      "                        can be used to specify options of the underlying\r\n",
      "                        cluster system, thereby using the job properties\r\n",
      "                        input, output, params, wildcards, log, threads and\r\n",
      "                        dependencies, e.g.: --drmaa ' -pe threaded {threads}'.\r\n",
      "                        Note that ARGS must be given in quotes and with a\r\n",
      "                        leading whitespace.\r\n",
      "  --drmaa-log-dir DIR   Specify a directory in which stdout and stderr files\r\n",
      "                        of DRMAA jobs will be written. The value may be given\r\n",
      "                        as a relative path, in which case Snakemake will use\r\n",
      "                        the current invocation directory as the origin. If\r\n",
      "                        given, this will override any given '-o' and/or '-e'\r\n",
      "                        native specification. If not given, all DRMAA stdout\r\n",
      "                        and stderr files are written to the current working\r\n",
      "                        directory.\r\n",
      "  --cluster-config FILE, -u FILE\r\n",
      "                        A JSON or YAML file that defines the wildcards used in\r\n",
      "                        'cluster'for specific rules, instead of having them\r\n",
      "                        specified in the Snakefile. For example, for rule\r\n",
      "                        'job' you may define: { 'job' : { 'time' : '24:00:00'\r\n",
      "                        } } to specify the time for rule 'job'. You can\r\n",
      "                        specify more than one file. The configuration files\r\n",
      "                        are merged with later values overriding earlier ones.\r\n",
      "  --immediate-submit, --is\r\n",
      "                        Immediately submit all jobs to the cluster instead of\r\n",
      "                        waiting for present input files. This will fail,\r\n",
      "                        unless you make the cluster aware of job dependencies,\r\n",
      "                        e.g. via: $ snakemake --cluster 'sbatch --dependency\r\n",
      "                        {dependencies}. Assuming that your submit script (here\r\n",
      "                        sbatch) outputs the generated job id to the first\r\n",
      "                        stdout line, {dependencies} will be filled with space\r\n",
      "                        separated job ids this job depends on.\r\n",
      "  --jobscript SCRIPT, --js SCRIPT\r\n",
      "                        Provide a custom job script for submission to the\r\n",
      "                        cluster. The default script resides as 'jobscript.sh'\r\n",
      "                        in the installation directory.\r\n",
      "  --jobname NAME, --jn NAME\r\n",
      "                        Provide a custom name for the jobscript that is\r\n",
      "                        submitted to the cluster (see --cluster). NAME is\r\n",
      "                        \"snakejob.{rulename}.{jobid}.sh\" per default. The\r\n",
      "                        wildcard {jobid} has to be present in the name.\r\n",
      "  --reason, -r          Print the reason for each executed rule.\r\n",
      "  --stats FILE          Write stats about Snakefile execution in JSON format\r\n",
      "                        to the given file.\r\n",
      "  --nocolor             Do not use a colored output.\r\n",
      "  --quiet, -q           Do not output any progress or rule information.\r\n",
      "  --nolock              Do not lock the working directory\r\n",
      "  --unlock              Remove a lock on the working directory.\r\n",
      "  --cleanup-metadata FILE [FILE ...], --cm FILE [FILE ...]\r\n",
      "                        Cleanup the metadata of given files. That means that\r\n",
      "                        snakemake removes any tracked version info, and any\r\n",
      "                        marks that files are incomplete.\r\n",
      "  --rerun-incomplete, --ri\r\n",
      "                        Re-run all jobs the output of which is recognized as\r\n",
      "                        incomplete.\r\n",
      "  --ignore-incomplete, --ii\r\n",
      "                        Do not check for incomplete output files.\r\n",
      "  --list-version-changes, --lv\r\n",
      "                        List all output files that have been created with a\r\n",
      "                        different version (as determined by the version\r\n",
      "                        keyword).\r\n",
      "  --list-code-changes, --lc\r\n",
      "                        List all output files for which the rule body (run or\r\n",
      "                        shell) have changed in the Snakefile.\r\n",
      "  --list-input-changes, --li\r\n",
      "                        List all output files for which the defined input\r\n",
      "                        files have changed in the Snakefile (e.g. new input\r\n",
      "                        files were added in the rule definition or files were\r\n",
      "                        renamed). For listing input file modification in the\r\n",
      "                        filesystem, use --summary.\r\n",
      "  --list-params-changes, --lp\r\n",
      "                        List all output files for which the defined params\r\n",
      "                        have changed in the Snakefile.\r\n",
      "  --latency-wait SECONDS, --output-wait SECONDS, -w SECONDS\r\n",
      "                        Wait given seconds if an output file of a job is not\r\n",
      "                        present after the job finished. This helps if your\r\n",
      "                        filesystem suffers from latency (default 5).\r\n",
      "  --wait-for-files [FILE [FILE ...]]\r\n",
      "                        Wait --latency-wait seconds for these files to be\r\n",
      "                        present before executing the workflow. This option is\r\n",
      "                        used internally to handle filesystem latency in\r\n",
      "                        cluster environments.\r\n",
      "  --benchmark-repeats N\r\n",
      "                        Repeat a job N times if marked for benchmarking\r\n",
      "                        (default 1).\r\n",
      "  --notemp, --nt        Ignore temp() declarations. This is useful when\r\n",
      "                        running only a part of the workflow, since temp()\r\n",
      "                        would lead to deletion of probably needed files by\r\n",
      "                        other parts of the workflow.\r\n",
      "  --keep-remote         Keep local copies of remote input files.\r\n",
      "  --keep-target-files   Do not adjust the paths of given target files relative\r\n",
      "                        to the working directory.\r\n",
      "  --keep-shadow         Do not delete the shadow directory on snakemake\r\n",
      "                        startup.\r\n",
      "  --allowed-rules ALLOWED_RULES [ALLOWED_RULES ...]\r\n",
      "                        Only consider given rules. If omitted, all rules in\r\n",
      "                        Snakefile are used. Note that this is intended\r\n",
      "                        primarily for internal use and may lead to unexpected\r\n",
      "                        results otherwise.\r\n",
      "  --max-jobs-per-second MAX_JOBS_PER_SECOND\r\n",
      "                        Maximal number of cluster/drmaa jobs per second,\r\n",
      "                        default is no limit\r\n",
      "  --restart-times RESTART_TIMES\r\n",
      "                        Number of times to restart failing jobs (defaults to\r\n",
      "                        0).\r\n",
      "  --timestamp, -T       Add a timestamp to all logging output\r\n",
      "  --greediness GREEDINESS\r\n",
      "                        Set the greediness of scheduling. This value between 0\r\n",
      "                        and 1 determines how careful jobs are selected for\r\n",
      "                        execution. The default value (1.0) provides the best\r\n",
      "                        speed and still acceptable scheduling quality.\r\n",
      "  --no-hooks            Do not invoke onstart, onsuccess or onerror hooks\r\n",
      "                        after execution.\r\n",
      "  --print-compilation   Print the python representation of the workflow.\r\n",
      "  --overwrite-shellcmd OVERWRITE_SHELLCMD\r\n",
      "                        Provide a shell command that shall be executed instead\r\n",
      "                        of those given in the workflow. This is for debugging\r\n",
      "                        purposes only.\r\n",
      "  --verbose             Print debugging output.\r\n",
      "  --debug               Allow to debug rules with e.g. PDB. This flag allows\r\n",
      "                        to set breakpoints in run blocks.\r\n",
      "  --profile FILE        Profile Snakemake and write the output to FILE. This\r\n",
      "                        requires yappi to be installed.\r\n",
      "  --mode {0,1,2}        Set execution mode of Snakemake (internal use only).\r\n",
      "  --bash-completion     Output code to register bash completion for snakemake.\r\n",
      "                        Put the following in your .bashrc (including the\r\n",
      "                        accents): `snakemake --bash-completion` or issue it in\r\n",
      "                        an open terminal session.\r\n",
      "  --use-conda           If defined in the rule, create job specific conda\r\n",
      "                        environments. If this flag is not set, the conda\r\n",
      "                        directive is ignored.\r\n",
      "  --conda-prefix DIR    Specify a directory in which the 'conda' and 'conda-\r\n",
      "                        archive' directories are created. These are used to\r\n",
      "                        store conda environments and their archives,\r\n",
      "                        respectively. If not supplied, the value is set to the\r\n",
      "                        '.snakemake' directory relative to the invocation\r\n",
      "                        directory. If supplied, the `--use-conda` flag must\r\n",
      "                        also be set. The value may be given as a relative\r\n",
      "                        path, which will be extrapolated to the invocation\r\n",
      "                        directory, or as an absolute path.\r\n",
      "  --wrapper-prefix WRAPPER_PREFIX\r\n",
      "                        Prefix for URL created from wrapper directive\r\n",
      "                        (default: https://bitbucket.org/snakemake/snakemake-\r\n",
      "                        wrappers/raw/). Set this to a different URL to use\r\n",
      "                        your fork or a local clone of the repository.\r\n",
      "  --default-remote-provider {S3,GS,SFTP,S3Mocked}\r\n",
      "                        Specify default remote provider to be used for all\r\n",
      "                        input and output files that don't yet specify one.\r\n",
      "  --default-remote-prefix DEFAULT_REMOTE_PREFIX\r\n",
      "                        Specify prefix for default remote provider. E.g. a\r\n",
      "                        bucket name.\r\n",
      "  --version, -v         show program's version number and exit\r\n"
     ]
    }
   ],
   "source": [
    "!snakemake -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49e109e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tall\n",
      "\t1\tconcat_files\n",
      "\t3\ttouch_files\n",
      "\t5\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mrule touch_files:\n",
      "    output: 3.txt\n",
      "    jobid: 3\n",
      "    wildcards: sample=3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "\u001b[32m1 of 5 steps (20%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mrule touch_files:\n",
      "    output: 2.txt\n",
      "    jobid: 4\n",
      "    wildcards: sample=2\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mFinished job 4.\u001b[0m\n",
      "\u001b[32m2 of 5 steps (40%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mrule touch_files:\n",
      "    output: 1.txt\n",
      "    jobid: 2\n",
      "    wildcards: sample=1\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m3 of 5 steps (60%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mrule concat_files:\n",
      "    input: 1.txt, 2.txt, 3.txt\n",
      "    output: combined_instructions.txt\n",
      "    jobid: 1\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m4 of 5 steps (80%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: combined_instructions.txt\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m5 of 5 steps (100%) done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -s snakefile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752fa60",
   "metadata": {},
   "source": [
    "We are now ready to do some advanced pipelining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4ce85",
   "metadata": {},
   "source": [
    "Example workflow: https://snakemake.readthedocs.io/en/stable/tutorial/basics.html#step-1-mapping-reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e66faa",
   "metadata": {},
   "source": [
    "Implementation of GATK-4 pipeline for exome analyses.\n",
    "https://github.com/mrinalmanu/gatk4_exome_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a0766",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ade53",
   "metadata": {},
   "source": [
    "Put 1.txt, 2.txt, and 3.txt in a folder called **input_directory**, and create an output directory. The snakemake pipeline should read the input from **input_directory**, and should make an output to **output_directory**\n",
    "\n",
    "During the appending of text, put your names after hello. You can also name one of the files after your name.\n",
    "\n",
    "Hint: You can add a variable called **input_dir** and **output_dir** to set paths within the config, or the snakemake file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f32ac",
   "metadata": {},
   "source": [
    "EON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smk] *",
   "language": "python",
   "name": "conda-env-smk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
